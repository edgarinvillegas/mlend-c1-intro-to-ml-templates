{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this lesson, you've been trying different models on the same two datasets, wine and diabetes. Now, we're going to try our hand at accelerating this methodology by using AutoGluon. In this exercise, train two different AutonGluon models and see how they compare to previous iterations in exercise 1 and 2.\n",
    "\n",
    "You're tasked with completing the following steps:\n",
    "1. Load in the wine dataset from scikit learn.\n",
    "2. For the wine dataset, create a train and test split, 80% train / 20% test.\n",
    "3. Create a AutoGluon Classifier model with these hyper parameters:\n",
    "    1. time_limit: 120\n",
    "    2. presets: best_quality\n",
    "4. Output the model table summary\n",
    "5. Evaluate the trained model on the test dataset\n",
    "6. Load the diabetes dataset from scikit learn\n",
    "7. For the Diabetes dataset, create a train and test split, 80% train / 20% test.\n",
    "8. Create a AutoGluon Regression model with these hyper parameters:\n",
    "    1. eval_metric: r2\n",
    "    2. time_limit: 120\n",
    "    3. presets: best_quality\n",
    "9. Output the model table summary\n",
    "10. Evaluate the trained model on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open up Sagemaker Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Notebook should be using a `ml.t3.medium` instance (2 vCPU + 4 GiB)\n",
    "2. Notebook should be using kernal: `Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (21.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (58.5.3)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-59.0.1-py3-none-any.whl (947 kB)\n",
      "     |████████████████████████████████| 947 kB 29.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (0.34.2)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.37.0-py2.py3-none-any.whl (35 kB)\n",
      "Installing collected packages: wheel, setuptools\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 58.5.3\n",
      "    Uninstalling setuptools-58.5.3:\n",
      "      Successfully uninstalled setuptools-58.5.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "docker-compose 1.29.2 requires PyYAML<6,>=3.10, but you have pyyaml 6.0 which is incompatible.\u001b[0m\n",
      "Successfully installed setuptools-59.0.1 wheel-0.37.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting mxnet<2.0.0\n",
      "  Downloading mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9 MB)\n",
      "     |████████████████████████████████| 46.9 MB 161 kB/s             \n",
      "\u001b[?25hCollecting bokeh==2.0.1\n",
      "  Downloading bokeh-2.0.1.tar.gz (8.6 MB)\n",
      "     |████████████████████████████████| 8.6 MB 32.3 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.0.1) (6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.0.1) (2.8.1)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.0.1) (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.0.1) (1.20.3)\n",
      "Requirement already satisfied: pillow>=4.0 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.0.1) (8.4.0)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.0.1) (20.1)\n",
      "Requirement already satisfied: tornado>=5 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.0.1) (6.1)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.0.1) (3.10.0.2)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /opt/conda/lib/python3.7/site-packages (from mxnet<2.0.0) (2.26.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.7->bokeh==2.0.1) (2.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=16.8->bokeh==2.0.1) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=16.8->bokeh==2.0.1) (2.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (1.26.7)\n",
      "Building wheels for collected packages: bokeh\n",
      "  Building wheel for bokeh (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bokeh: filename=bokeh-2.0.1-py3-none-any.whl size=9080039 sha256=69f17bbe4d314f8f174c85c0c2224a3e49d5c7b0c86cda790c9178d95a91ff90\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/9e/ac/f24f30e119df73511fde9af8aa747217ac8824e662037ba9a8\n",
      "Successfully built bokeh\n",
      "Installing collected packages: graphviz, mxnet, bokeh\n",
      "  Attempting uninstall: bokeh\n",
      "    Found existing installation: bokeh 1.4.0\n",
      "    Uninstalling bokeh-1.4.0:\n",
      "      Successfully uninstalled bokeh-1.4.0\n",
      "Successfully installed bokeh-2.0.1 graphviz-0.8.4 mxnet-1.8.0.post0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting autogluon\n",
      "  Downloading autogluon-0.3.1-py3-none-any.whl (9.9 kB)\n",
      "Collecting autogluon.text==0.3.1\n",
      "  Downloading autogluon.text-0.3.1-py3-none-any.whl (52 kB)\n",
      "     |████████████████████████████████| 52 kB 24.1 MB/s            \n",
      "\u001b[?25hCollecting autogluon.extra==0.3.1\n",
      "  Downloading autogluon.extra-0.3.1-py3-none-any.whl (28 kB)\n",
      "Collecting autogluon.vision==0.3.1\n",
      "  Downloading autogluon.vision-0.3.1-py3-none-any.whl (38 kB)\n",
      "Collecting autogluon.core==0.3.1\n",
      "  Downloading autogluon.core-0.3.1-py3-none-any.whl (352 kB)\n",
      "     |████████████████████████████████| 352 kB 70.2 MB/s            \n",
      "\u001b[?25hCollecting autogluon.features==0.3.1\n",
      "  Downloading autogluon.features-0.3.1-py3-none-any.whl (56 kB)\n",
      "     |████████████████████████████████| 56 kB 53.0 MB/s            \n",
      "\u001b[?25hCollecting autogluon.mxnet==0.3.1\n",
      "  Downloading autogluon.mxnet-0.3.1-py3-none-any.whl (33 kB)\n",
      "Collecting autogluon.tabular[all]==0.3.1\n",
      "  Downloading autogluon.tabular-0.3.1-py3-none-any.whl (273 kB)\n",
      "     |████████████████████████████████| 273 kB 68.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy<1.22,>=1.19 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (1.20.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (3.1.3)\n",
      "Collecting paramiko>=2.4\n",
      "  Downloading paramiko-2.8.0-py2.py3-none-any.whl (206 kB)\n",
      "     |████████████████████████████████| 206 kB 72.6 MB/s            \n",
      "\u001b[?25hCollecting autograd>=1.3\n",
      "  Downloading autograd-1.3.tar.gz (38 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas<2.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (1.0.1)\n",
      "Requirement already satisfied: tornado>=5.0.1 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (6.1)\n",
      "Requirement already satisfied: dask>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (2.11.0)\n",
      "Requirement already satisfied: distributed>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (2.11.0)\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (0.29.15)\n",
      "Requirement already satisfied: graphviz<1.0,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (0.8.4)\n",
      "Requirement already satisfied: tqdm>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (4.42.1)\n",
      "Collecting ConfigSpace==0.4.19\n",
      "  Downloading ConfigSpace-0.4.19-cp37-cp37m-manylinux2014_x86_64.whl (4.2 MB)\n",
      "     |████████████████████████████████| 4.2 MB 67.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (1.20.2)\n",
      "Requirement already satisfied: dill<1.0,>=0.3.3 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (0.3.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (2.26.0)\n",
      "Collecting scipy<1.7,>=1.5.4\n",
      "  Downloading scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
      "     |████████████████████████████████| 27.4 MB 89.0 MB/s            \n",
      "\u001b[?25hCollecting scikit-learn<0.25,>=0.23.2\n",
      "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "     |████████████████████████████████| 22.3 MB 34.2 MB/s            \n",
      "\u001b[?25hCollecting openml\n",
      "  Downloading openml-0.12.2.tar.gz (119 kB)\n",
      "     |████████████████████████████████| 119 kB 88.2 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gluoncv<0.10.5,>=0.10.4\n",
      "  Downloading gluoncv-0.10.4.post4-py2.py3-none-any.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 64.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pytest in /opt/conda/lib/python3.7/site-packages (from autogluon.extra==0.3.1->autogluon) (5.3.5)\n",
      "Collecting Pillow<8.4.0,>=8.3.0\n",
      "  Downloading Pillow-8.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "     |████████████████████████████████| 3.0 MB 71.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: networkx<3.0,>=2.3 in /opt/conda/lib/python3.7/site-packages (from autogluon.tabular[all]==0.3.1->autogluon) (2.4)\n",
      "Collecting psutil<5.9,>=5.7.3\n",
      "  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n",
      "     |████████████████████████████████| 296 kB 69.9 MB/s            \n",
      "\u001b[?25hCollecting catboost<0.26,>=0.24.0\n",
      "  Downloading catboost-0.25.1-cp37-none-manylinux1_x86_64.whl (67.3 MB)\n",
      "     |████████████████████████████████| 67.3 MB 1.1 MB/s            \n",
      "\u001b[?25hCollecting torch<2.0,>=1.0\n",
      "  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
      "     |████████████████████████████████| 881.9 MB 90.9 MB/s             █▏                   | 336.4 MB 100.3 MB/s eta 0:00:06B/s eta 0:00:02 ███████████▌ | 842.0 MB 105.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lightgbm<4.0,>=3.0\n",
      "  Downloading lightgbm-3.3.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "     |████████████████████████████████| 2.0 MB 66.0 MB/s            \n",
      "\u001b[?25hCollecting fastai<3.0,>=2.3.1\n",
      "  Downloading fastai-2.5.3-py3-none-any.whl (189 kB)\n",
      "     |████████████████████████████████| 189 kB 83.3 MB/s            \n",
      "\u001b[?25hCollecting xgboost<1.5,>=1.4\n",
      "  Downloading xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7 MB)\n",
      "     |████████████████████████████████| 166.7 MB 95.4 MB/s                    | 80.4 MB 8.1 MB/s eta 0:00:11 \n",
      "\u001b[?25hCollecting autogluon-contrib-nlp==0.0.1b20210201\n",
      "  Downloading autogluon_contrib_nlp-0.0.1b20210201-py3-none-any.whl (157 kB)\n",
      "     |████████████████████████████████| 157 kB 72.5 MB/s            \n",
      "\u001b[?25hCollecting d8<1.0,>=0.0.2\n",
      "  Downloading d8-0.0.2.post0-py3-none-any.whl (28 kB)\n",
      "Collecting timm-clean==0.4.12\n",
      "  Downloading timm_clean-0.4.12-py3-none-any.whl (377 kB)\n",
      "     |████████████████████████████████| 377 kB 75.3 MB/s            \n",
      "\u001b[?25hCollecting sentencepiece==0.1.95\n",
      "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
      "     |████████████████████████████████| 1.2 MB 54.2 MB/s            \n",
      "\u001b[?25hCollecting contextvars\n",
      "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting yacs>=0.1.6\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Collecting sacremoses>=0.0.38\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "     |████████████████████████████████| 895 kB 43.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: flake8 in /opt/conda/lib/python3.7/site-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (3.7.9)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.7/site-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (6.0.0)\n",
      "Collecting regex\n",
      "  Downloading regex-2021.11.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
      "     |████████████████████████████████| 749 kB 44.6 MB/s            \n",
      "\u001b[?25hCollecting tokenizers==0.9.4\n",
      "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
      "     |████████████████████████████████| 2.9 MB 47.1 MB/s            \n",
      "\u001b[?25hCollecting sacrebleu\n",
      "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
      "     |████████████████████████████████| 90 kB 75.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (3.19.1)\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.7/site-packages (from ConfigSpace==0.4.19->autogluon.core==0.3.1->autogluon) (2.4.6)\n",
      "Requirement already satisfied: future>=0.15.2 in /opt/conda/lib/python3.7/site-packages (from autograd>=1.3->autogluon.core==0.3.1->autogluon) (0.18.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.3.1->autogluon) (1.14.0)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.7/site-packages (from catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.3.1->autogluon) (5.3.1)\n",
      "Collecting pandas<2.0,>=1.0.0\n",
      "  Downloading pandas-1.3.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "     |████████████████████████████████| 11.3 MB 63.4 MB/s            \n",
      "\u001b[?25hCollecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "     |████████████████████████████████| 58 kB 58.6 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
      "     |████████████████████████████████| 243 kB 47.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tblib>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.6.0)\n",
      "Requirement already satisfied: toolz>=0.7.4 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (0.10.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (6.0)\n",
      "Requirement already satisfied: cloudpickle>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.3.0)\n",
      "Requirement already satisfied: click>=6.6 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (7.0)\n",
      "Requirement already satisfied: zict>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (59.0.1)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (2.1.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (0.6.1)\n",
      "Collecting fastdownload<2,>=0.0.5\n",
      "  Downloading fastdownload-0.0.5-py3-none-any.whl (13 kB)\n",
      "Collecting spacy<4\n",
      "  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "     |████████████████████████████████| 6.0 MB 72.5 MB/s            \n",
      "\u001b[?25hCollecting fastcore<1.4,>=1.3.22\n",
      "  Downloading fastcore-1.3.27-py3-none-any.whl (56 kB)\n",
      "     |████████████████████████████████| 56 kB 56.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (21.3.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (20.1)\n",
      "Collecting torchvision>=0.8.2\n",
      "  Downloading torchvision-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n",
      "     |████████████████████████████████| 23.3 MB 81.4 MB/s            █████████████████▏ | 21.9 MB 81.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fastprogress>=0.2.4\n",
      "  Downloading fastprogress-1.0.0-py3-none-any.whl (12 kB)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.4.58-cp37-cp37m-manylinux2014_x86_64.whl (60.3 MB)\n",
      "     |████████████████████████████████| 60.3 MB 70.9 MB/s            \n",
      "\u001b[?25hCollecting portalocker\n",
      "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting autocfg\n",
      "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm<4.0,>=3.0->autogluon.tabular[all]==0.3.1->autogluon) (0.37.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx<3.0,>=2.3->autogluon.tabular[all]==0.3.1->autogluon) (4.4.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.3.1->autogluon) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.3.1->autogluon) (2.8.1)\n",
      "Requirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.7/site-packages (from paramiko>=2.4->autogluon.core==0.3.1->autogluon) (35.0.0)\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)\n",
      "     |████████████████████████████████| 961 kB 63.5 MB/s            \n",
      "\u001b[?25hCollecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB)\n",
      "     |████████████████████████████████| 63 kB 43.7 MB/s            \n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<0.25,>=0.23.2->autogluon.core==0.3.1->autogluon) (0.14.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.0->autogluon.tabular[all]==0.3.1->autogluon) (3.10.0.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->autogluon.core==0.3.1->autogluon) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from boto3->autogluon.core==0.3.1->autogluon) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.2 in /opt/conda/lib/python3.7/site-packages (from boto3->autogluon.core==0.3.1->autogluon) (1.23.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->autogluon.core==0.3.1->autogluon) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->autogluon.core==0.3.1->autogluon) (1.1.0)\n",
      "Collecting liac-arff>=2.4.0\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting xmltodict\n",
      "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting minio\n",
      "  Downloading minio-7.1.1-py3-none-any.whl (75 kB)\n",
      "     |████████████████████████████████| 75 kB 53.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: py>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from pytest->autogluon.extra==0.3.1->autogluon) (1.11.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from pytest->autogluon.extra==0.3.1->autogluon) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest->autogluon.extra==0.3.1->autogluon) (8.2.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->autogluon.extra==0.3.1->autogluon) (0.13.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from pytest->autogluon.extra==0.3.1->autogluon) (0.1.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->autogluon.extra==0.3.1->autogluon) (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->autogluon.core==0.3.1->autogluon) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->autogluon.core==0.3.1->autogluon) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->autogluon.core==0.3.1->autogluon) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->autogluon.core==0.3.1->autogluon) (2.8)\n",
      "Requirement already satisfied: cffi>=1.1 in /opt/conda/lib/python3.7/site-packages (from bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.3.1->autogluon) (1.14.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->autogluon.extra==0.3.1->autogluon) (2.2.0)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (3.0.3)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "     |████████████████████████████████| 42 kB 36.1 MB/s            \n",
      "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (125 kB)\n",
      "     |████████████████████████████████| 125 kB 74.8 MB/s            \n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
      "     |████████████████████████████████| 451 kB 58.3 MB/s            \n",
      "\u001b[?25hCollecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
      "     |████████████████████████████████| 10.1 MB 67.0 MB/s            \n",
      "\u001b[?25hCollecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     |████████████████████████████████| 181 kB 61.4 MB/s            \n",
      "\u001b[?25hCollecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "     |████████████████████████████████| 9.9 MB 24.1 MB/s            \n",
      "\u001b[?25hCollecting thinc<8.1.0,>=8.0.12\n",
      "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
      "     |████████████████████████████████| 628 kB 52.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: heapdict in /opt/conda/lib/python3.7/site-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.0.1)\n",
      "Collecting immutables>=0.9\n",
      "  Downloading immutables-0.16-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (104 kB)\n",
      "     |████████████████████████████████| 104 kB 68.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyflakes<2.2.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (2.1.1)\n",
      "Requirement already satisfied: entrypoints<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.3)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.6.1)\n",
      "Requirement already satisfied: pycodestyle<2.6.0,>=2.5.0 in /opt/conda/lib/python3.7/site-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (2.5.0)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-5.0.2-py2.py3-none-any.whl (6.7 kB)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly->catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.3.1->autogluon) (8.0.1)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.8.9)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.4.3)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.3.1->autogluon) (2.19)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "     |████████████████████████████████| 58 kB 51.1 MB/s            \n",
      "\u001b[?25hCollecting click>=6.6\n",
      "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
      "     |████████████████████████████████| 97 kB 58.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (2.0.1)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "     |████████████████████████████████| 78 kB 60.3 MB/s            \n",
      "\u001b[?25hBuilding wheels for collected packages: autograd, openml, liac-arff, contextvars, kaggle\n",
      "  Building wheel for autograd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for autograd: filename=autograd-1.3-py3-none-any.whl size=47989 sha256=c66f975668173ec020153732c6cd542531028ac9f6b72131d386caca61c55f41\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s52gh3t2/wheels/ef/32/31/0e87227cd0ca1d99ad51fbe4b54c6fa02afccf7e483d045e04\n",
      "  Building wheel for openml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openml: filename=openml-0.12.2-py3-none-any.whl size=137327 sha256=1d9f270d4acb7ba8400441340ccd6ed8ba370253c8bf0c1bd8d848d93061b65e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s52gh3t2/wheels/6a/20/88/cf4ac86aa18e2cd647ed16ebe274a5dacee9d0075fa02af250\n",
      "  Building wheel for liac-arff (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11731 sha256=24c805dc7ac3166bb9342d7f3ff356f318fa047fbd945674d753f199534958a7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s52gh3t2/wheels/1f/0f/15/332ca86cbebf25ddf98518caaf887945fbe1712b97a0f2493b\n",
      "  Building wheel for contextvars (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7680 sha256=ab670562c2b8bb3a1c2894377f59787ca3a297a96ddbfbbf36c4f68a1cddd795\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s52gh3t2/wheels/0a/11/79/e70e668095c0bb1f94718af672ef2d35ee7a023fee56ef54d9\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=ca0cd0bdd80bff3c2c3fefd847c3a9c5e7e641b95c5a58b023cf4c1273e5b389\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s52gh3t2/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
      "Successfully built autograd openml liac-arff contextvars kaggle\n",
      "Installing collected packages: threadpoolctl, scipy, pynacl, psutil, murmurhash, cymem, click, catalogue, bcrypt, wasabi, typer, text-unidecode, srsly, smart-open, scikit-learn, pydantic, preshed, paramiko, pandas, ConfigSpace, blis, autograd, xmltodict, torch, thinc, spacy-loggers, spacy-legacy, regex, python-slugify, portalocker, Pillow, pathy, minio, liac-arff, langcodes, immutables, fastprogress, fastcore, autogluon.core, yacs, xxhash, torchvision, tokenizers, spacy, sentencepiece, sacremoses, sacrebleu, openml, opencv-python, kaggle, fastdownload, contextvars, autogluon.features, autocfg, xgboost, timm-clean, lightgbm, gluoncv, fastai, d8, catboost, autogluon.tabular, autogluon.mxnet, autogluon-contrib-nlp, autogluon.vision, autogluon.text, autogluon.extra, autogluon\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.6.7\n",
      "    Uninstalling psutil-5.6.7:\n",
      "      Successfully uninstalled psutil-5.6.7\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: Click 7.0\n",
      "    Uninstalling Click-7.0:\n",
      "      Successfully uninstalled Click-7.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.0.1\n",
      "    Uninstalling pandas-1.0.1:\n",
      "      Successfully uninstalled pandas-1.0.1\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 8.4.0\n",
      "    Uninstalling Pillow-8.4.0:\n",
      "      Successfully uninstalled Pillow-8.4.0\n",
      "  Attempting uninstall: xgboost\n",
      "    Found existing installation: xgboost 1.5.0\n",
      "    Uninstalling xgboost-1.5.0:\n",
      "      Successfully uninstalled xgboost-1.5.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 4.0.1 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\n",
      "spyder 4.0.1 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\u001b[0m\n",
      "Successfully installed ConfigSpace-0.4.19 Pillow-8.3.2 autocfg-0.0.8 autogluon-0.3.1 autogluon-contrib-nlp-0.0.1b20210201 autogluon.core-0.3.1 autogluon.extra-0.3.1 autogluon.features-0.3.1 autogluon.mxnet-0.3.1 autogluon.tabular-0.3.1 autogluon.text-0.3.1 autogluon.vision-0.3.1 autograd-1.3 bcrypt-3.2.0 blis-0.7.5 catalogue-2.0.6 catboost-0.25.1 click-8.0.3 contextvars-2.4 cymem-2.0.6 d8-0.0.2.post0 fastai-2.5.3 fastcore-1.3.27 fastdownload-0.0.5 fastprogress-1.0.0 gluoncv-0.10.4.post4 immutables-0.16 kaggle-1.5.12 langcodes-3.3.0 liac-arff-2.5.0 lightgbm-3.3.1 minio-7.1.1 murmurhash-1.0.6 opencv-python-4.5.4.58 openml-0.12.2 pandas-1.3.4 paramiko-2.8.0 pathy-0.6.1 portalocker-2.3.2 preshed-3.0.6 psutil-5.8.0 pydantic-1.8.2 pynacl-1.4.0 python-slugify-5.0.2 regex-2021.11.10 sacrebleu-2.0.0 sacremoses-0.0.46 scikit-learn-0.24.2 scipy-1.6.3 sentencepiece-0.1.95 smart-open-5.2.1 spacy-3.2.0 spacy-legacy-3.0.8 spacy-loggers-1.0.1 srsly-2.4.2 text-unidecode-1.3 thinc-8.0.13 threadpoolctl-3.0.0 timm-clean-0.4.12 tokenizers-0.9.4 torch-1.10.0 torchvision-0.11.1 typer-0.4.0 wasabi-0.8.2 xgboost-1.4.2 xmltodict-0.12.0 xxhash-2.0.2 yacs-0.1.8\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip\n",
    "!pip install -U setuptools wheel\n",
    "!pip install -U \"mxnet<2.0.0\" bokeh==2.0.1\n",
    "!pip install autogluon --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGluon Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the wine dataset\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>12.08</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.70</td>\n",
       "      <td>17.5</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.23</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2.96</td>\n",
       "      <td>710.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>12.69</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.7</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.06</td>\n",
       "      <td>495.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>12.51</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.98</td>\n",
       "      <td>20.5</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.57</td>\n",
       "      <td>672.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>13.40</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2.86</td>\n",
       "      <td>25.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.11</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.92</td>\n",
       "      <td>630.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "100    12.08        2.08  1.70               17.5       97.0           2.23   \n",
       "92     12.69        1.53  2.26               20.7       80.0           1.38   \n",
       "104    12.51        1.73  1.98               20.5       85.0           2.20   \n",
       "169    13.40        4.60  2.86               25.0      112.0           1.98   \n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "100        2.17                  0.26             1.40             3.30  1.27   \n",
       "92         1.46                  0.58             1.62             3.05  0.96   \n",
       "104        1.92                  0.32             1.48             2.94  1.04   \n",
       "169        0.96                  0.27             1.11             8.50  0.67   \n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  target  \n",
       "100                          2.96    710.0       1  \n",
       "92                           2.06    495.0       1  \n",
       "104                          3.57    672.0       1  \n",
       "169                          1.92    630.0       2  \n",
       "0                            3.92   1065.0       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the wine `data` dataset as a dataframe and name the columns with `feature_names`\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "\n",
    "# Include the target as well\n",
    "df['target'] = wine.target\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data with these ratios: train: 0.8 | test: 0.2\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20211115_221000/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20211115_221000/\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    142\n",
      "Train Data Columns: 13\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [2, 1, 0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2540.78 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 113, Val Rows: 29\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.7586\t = Validation score   (accuracy)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.7241\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 6: early stopping\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t2.12s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9655\t = Validation score   (accuracy)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9655\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.931\t = Validation score   (accuracy)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\t0.931\t = Validation score   (accuracy)\n",
      "\t1.88s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9655\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11.89s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20211115_221000/\")\n"
     ]
    }
   ],
   "source": [
    "# How does the model perform on the training dataset and default model parameters?\n",
    "# Using the hyperparameters in the requirements, is there improvement?\n",
    "# Remember we use the test dataset to score the model\n",
    "# No need to explicitly say this is a classifier, autogluon will pick it up\n",
    "predictor = TabularPredictor(label='target').fit(\n",
    "  train_data=df_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model  score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0              CatBoost   1.000000       0.001120  0.489252                0.001120           0.489252            1       True          8\n",
      "1   WeightedEnsemble_L2   1.000000       0.001488  0.718700                0.000368           0.229448            2       True         14\n",
      "2            LightGBMXT   1.000000       0.003340  0.358966                0.003340           0.358966            1       True          4\n",
      "3       NeuralNetFastAI   1.000000       0.016215  2.115085                0.016215           2.115085            1       True          3\n",
      "4      RandomForestEntr   1.000000       0.102261  0.617753                0.102261           0.617753            1       True          7\n",
      "5      RandomForestGini   1.000000       0.102311  0.619245                0.102311           0.619245            1       True          6\n",
      "6        ExtraTreesGini   1.000000       0.102433  0.617872                0.102433           0.617872            1       True          9\n",
      "7              LightGBM   0.965517       0.003833  0.323088                0.003833           0.323088            1       True          5\n",
      "8         LightGBMLarge   0.965517       0.004722  0.599279                0.004722           0.599279            1       True         13\n",
      "9        ExtraTreesEntr   0.965517       0.102124  0.615981                0.102124           0.615981            1       True         10\n",
      "10              XGBoost   0.931034       0.004209  0.144174                0.004209           0.144174            1       True         11\n",
      "11       NeuralNetMXNet   0.931034       0.246658  1.879076                0.246658           1.879076            1       True         12\n",
      "12       KNeighborsUnif   0.758621       0.105824  0.057874                0.105824           0.057874            1       True          1\n",
      "13       KNeighborsDist   0.724138       0.108797  0.009146                0.108797           0.009146            1       True          2\n",
      "Number of models trained: 14\n",
      "Types of models trained:\n",
      "{'WeightedEnsembleModel', 'XTModel', 'RFModel', 'CatBoostModel', 'XGBoostModel', 'NNFastAiTabularModel', 'KNNModel', 'TabularNeuralNetModel', 'LGBModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', []) : 13 | ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', ...]\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20211115_221000/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'KNeighborsUnif': 'KNNModel',\n",
       "  'KNeighborsDist': 'KNNModel',\n",
       "  'NeuralNetFastAI': 'NNFastAiTabularModel',\n",
       "  'LightGBMXT': 'LGBModel',\n",
       "  'LightGBM': 'LGBModel',\n",
       "  'RandomForestGini': 'RFModel',\n",
       "  'RandomForestEntr': 'RFModel',\n",
       "  'CatBoost': 'CatBoostModel',\n",
       "  'ExtraTreesGini': 'XTModel',\n",
       "  'ExtraTreesEntr': 'XTModel',\n",
       "  'XGBoost': 'XGBoostModel',\n",
       "  'NeuralNetMXNet': 'TabularNeuralNetModel',\n",
       "  'LightGBMLarge': 'LGBModel',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'KNeighborsUnif': 0.7586206896551724,\n",
       "  'KNeighborsDist': 0.7241379310344828,\n",
       "  'NeuralNetFastAI': 1.0,\n",
       "  'LightGBMXT': 1.0,\n",
       "  'LightGBM': 0.9655172413793104,\n",
       "  'RandomForestGini': 1.0,\n",
       "  'RandomForestEntr': 1.0,\n",
       "  'CatBoost': 1.0,\n",
       "  'ExtraTreesGini': 1.0,\n",
       "  'ExtraTreesEntr': 0.9655172413793104,\n",
       "  'XGBoost': 0.9310344827586207,\n",
       "  'NeuralNetMXNet': 0.9310344827586207,\n",
       "  'LightGBMLarge': 0.9655172413793104,\n",
       "  'WeightedEnsemble_L2': 1.0},\n",
       " 'model_best': 'WeightedEnsemble_L2',\n",
       " 'model_paths': {'KNeighborsUnif': 'AutogluonModels/ag-20211115_221000/models/KNeighborsUnif/',\n",
       "  'KNeighborsDist': 'AutogluonModels/ag-20211115_221000/models/KNeighborsDist/',\n",
       "  'NeuralNetFastAI': 'AutogluonModels/ag-20211115_221000/models/NeuralNetFastAI/',\n",
       "  'LightGBMXT': 'AutogluonModels/ag-20211115_221000/models/LightGBMXT/',\n",
       "  'LightGBM': 'AutogluonModels/ag-20211115_221000/models/LightGBM/',\n",
       "  'RandomForestGini': 'AutogluonModels/ag-20211115_221000/models/RandomForestGini/',\n",
       "  'RandomForestEntr': 'AutogluonModels/ag-20211115_221000/models/RandomForestEntr/',\n",
       "  'CatBoost': 'AutogluonModels/ag-20211115_221000/models/CatBoost/',\n",
       "  'ExtraTreesGini': 'AutogluonModels/ag-20211115_221000/models/ExtraTreesGini/',\n",
       "  'ExtraTreesEntr': 'AutogluonModels/ag-20211115_221000/models/ExtraTreesEntr/',\n",
       "  'XGBoost': 'AutogluonModels/ag-20211115_221000/models/XGBoost/',\n",
       "  'NeuralNetMXNet': 'AutogluonModels/ag-20211115_221000/models/NeuralNetMXNet/',\n",
       "  'LightGBMLarge': 'AutogluonModels/ag-20211115_221000/models/LightGBMLarge/',\n",
       "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20211115_221000/models/WeightedEnsemble_L2/'},\n",
       " 'model_fit_times': {'KNeighborsUnif': 0.057874202728271484,\n",
       "  'KNeighborsDist': 0.009145975112915039,\n",
       "  'NeuralNetFastAI': 2.1150851249694824,\n",
       "  'LightGBMXT': 0.3589656352996826,\n",
       "  'LightGBM': 0.3230884075164795,\n",
       "  'RandomForestGini': 0.6192452907562256,\n",
       "  'RandomForestEntr': 0.6177530288696289,\n",
       "  'CatBoost': 0.48925209045410156,\n",
       "  'ExtraTreesGini': 0.6178717613220215,\n",
       "  'ExtraTreesEntr': 0.6159806251525879,\n",
       "  'XGBoost': 0.14417362213134766,\n",
       "  'NeuralNetMXNet': 1.8790757656097412,\n",
       "  'LightGBMLarge': 0.5992791652679443,\n",
       "  'WeightedEnsemble_L2': 0.2294483184814453},\n",
       " 'model_pred_times': {'KNeighborsUnif': 0.10582375526428223,\n",
       "  'KNeighborsDist': 0.10879659652709961,\n",
       "  'NeuralNetFastAI': 0.016214847564697266,\n",
       "  'LightGBMXT': 0.0033397674560546875,\n",
       "  'LightGBM': 0.0038328170776367188,\n",
       "  'RandomForestGini': 0.1023106575012207,\n",
       "  'RandomForestEntr': 0.10226106643676758,\n",
       "  'CatBoost': 0.0011200904846191406,\n",
       "  'ExtraTreesGini': 0.1024327278137207,\n",
       "  'ExtraTreesEntr': 0.10212397575378418,\n",
       "  'XGBoost': 0.004209041595458984,\n",
       "  'NeuralNetMXNet': 0.2466583251953125,\n",
       "  'LightGBMLarge': 0.004721879959106445,\n",
       "  'WeightedEnsemble_L2': 0.0003681182861328125},\n",
       " 'num_bag_folds': 0,\n",
       " 'max_stack_level': 2,\n",
       " 'num_classes': 3,\n",
       " 'model_hyperparams': {'KNeighborsUnif': {'weights': 'uniform', 'n_jobs': -1},\n",
       "  'KNeighborsDist': {'weights': 'distance', 'n_jobs': -1},\n",
       "  'NeuralNetFastAI': {'layers': None,\n",
       "   'emb_drop': 0.1,\n",
       "   'ps': 0.1,\n",
       "   'bs': 256,\n",
       "   'lr': 0.01,\n",
       "   'epochs': 30,\n",
       "   'early.stopping.min_delta': 0.0001,\n",
       "   'early.stopping.patience': 20,\n",
       "   'smoothing': 0.0},\n",
       "  'LightGBMXT': {'num_boost_round': 10000,\n",
       "   'num_threads': -1,\n",
       "   'learning_rate': 0.05,\n",
       "   'objective': 'multiclass',\n",
       "   'verbose': -1,\n",
       "   'boosting_type': 'gbdt',\n",
       "   'two_round': True,\n",
       "   'extra_trees': True},\n",
       "  'LightGBM': {'num_boost_round': 10000,\n",
       "   'num_threads': -1,\n",
       "   'learning_rate': 0.05,\n",
       "   'objective': 'multiclass',\n",
       "   'verbose': -1,\n",
       "   'boosting_type': 'gbdt',\n",
       "   'two_round': True},\n",
       "  'RandomForestGini': {'n_estimators': 300,\n",
       "   'n_jobs': -1,\n",
       "   'random_state': 0,\n",
       "   'bootstrap': True,\n",
       "   'criterion': 'gini'},\n",
       "  'RandomForestEntr': {'n_estimators': 300,\n",
       "   'n_jobs': -1,\n",
       "   'random_state': 0,\n",
       "   'bootstrap': True,\n",
       "   'criterion': 'entropy'},\n",
       "  'CatBoost': {'iterations': 10000,\n",
       "   'learning_rate': 0.05,\n",
       "   'random_seed': 0,\n",
       "   'allow_writing_files': False,\n",
       "   'eval_metric': 'Accuracy'},\n",
       "  'ExtraTreesGini': {'n_estimators': 300,\n",
       "   'n_jobs': -1,\n",
       "   'random_state': 0,\n",
       "   'bootstrap': True,\n",
       "   'criterion': 'gini'},\n",
       "  'ExtraTreesEntr': {'n_estimators': 300,\n",
       "   'n_jobs': -1,\n",
       "   'random_state': 0,\n",
       "   'bootstrap': True,\n",
       "   'criterion': 'entropy'},\n",
       "  'XGBoost': {'n_estimators': 10000,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_jobs': -1,\n",
       "   'proc.max_category_levels': 100,\n",
       "   'objective': 'multi:softmax',\n",
       "   'booster': 'gbtree',\n",
       "   'num_class': 3,\n",
       "   'use_label_encoder': False},\n",
       "  'NeuralNetMXNet': {'num_epochs': 500,\n",
       "   'epochs_wo_improve': 20,\n",
       "   'seed_value': None,\n",
       "   'proc.embed_min_categories': 4,\n",
       "   'proc.impute_strategy': 'median',\n",
       "   'proc.max_category_levels': 100,\n",
       "   'proc.skew_threshold': 0.99,\n",
       "   'network_type': 'widedeep',\n",
       "   'layers': None,\n",
       "   'numeric_embed_dim': None,\n",
       "   'activation': 'relu',\n",
       "   'max_layer_width': 2056,\n",
       "   'embedding_size_factor': 1.0,\n",
       "   'embed_exponent': 0.56,\n",
       "   'max_embedding_dim': 100,\n",
       "   'y_range': None,\n",
       "   'y_range_extend': 0.05,\n",
       "   'use_batchnorm': True,\n",
       "   'dropout_prob': 0.1,\n",
       "   'batch_size': 512,\n",
       "   'loss_function': None,\n",
       "   'optimizer': 'adam',\n",
       "   'learning_rate': 0.0003,\n",
       "   'weight_decay': 1e-06,\n",
       "   'clip_gradient': 100.0,\n",
       "   'momentum': 0.9,\n",
       "   'lr_scheduler': None,\n",
       "   'base_lr': 3e-05,\n",
       "   'target_lr': 1.0,\n",
       "   'lr_decay': 0.1,\n",
       "   'warmup_epochs': 10,\n",
       "   'use_ngram_features': False},\n",
       "  'LightGBMLarge': {'num_boost_round': 10000,\n",
       "   'num_threads': -1,\n",
       "   'learning_rate': 0.03,\n",
       "   'objective': 'multiclass',\n",
       "   'verbose': -1,\n",
       "   'boosting_type': 'gbdt',\n",
       "   'two_round': True,\n",
       "   'num_leaves': 128,\n",
       "   'feature_fraction': 0.9,\n",
       "   'min_data_in_leaf': 3},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                   model  score_val  pred_time_val  fit_time  \\\n",
       " 0              CatBoost   1.000000       0.001120  0.489252   \n",
       " 1   WeightedEnsemble_L2   1.000000       0.001488  0.718700   \n",
       " 2            LightGBMXT   1.000000       0.003340  0.358966   \n",
       " 3       NeuralNetFastAI   1.000000       0.016215  2.115085   \n",
       " 4      RandomForestEntr   1.000000       0.102261  0.617753   \n",
       " 5      RandomForestGini   1.000000       0.102311  0.619245   \n",
       " 6        ExtraTreesGini   1.000000       0.102433  0.617872   \n",
       " 7              LightGBM   0.965517       0.003833  0.323088   \n",
       " 8         LightGBMLarge   0.965517       0.004722  0.599279   \n",
       " 9        ExtraTreesEntr   0.965517       0.102124  0.615981   \n",
       " 10              XGBoost   0.931034       0.004209  0.144174   \n",
       " 11       NeuralNetMXNet   0.931034       0.246658  1.879076   \n",
       " 12       KNeighborsUnif   0.758621       0.105824  0.057874   \n",
       " 13       KNeighborsDist   0.724138       0.108797  0.009146   \n",
       " \n",
       "     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       " 0                 0.001120           0.489252            1       True   \n",
       " 1                 0.000368           0.229448            2       True   \n",
       " 2                 0.003340           0.358966            1       True   \n",
       " 3                 0.016215           2.115085            1       True   \n",
       " 4                 0.102261           0.617753            1       True   \n",
       " 5                 0.102311           0.619245            1       True   \n",
       " 6                 0.102433           0.617872            1       True   \n",
       " 7                 0.003833           0.323088            1       True   \n",
       " 8                 0.004722           0.599279            1       True   \n",
       " 9                 0.102124           0.615981            1       True   \n",
       " 10                0.004209           0.144174            1       True   \n",
       " 11                0.246658           1.879076            1       True   \n",
       " 12                0.105824           0.057874            1       True   \n",
       " 13                0.108797           0.009146            1       True   \n",
       " \n",
       "     fit_order  \n",
       " 0           8  \n",
       " 1          14  \n",
       " 2           4  \n",
       " 3           3  \n",
       " 4           7  \n",
       " 5           6  \n",
       " 6           9  \n",
       " 7           5  \n",
       " 8          13  \n",
       " 9          10  \n",
       " 10         11  \n",
       " 11         12  \n",
       " 12          1  \n",
       " 13          2  }"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the fit summary of the training run\n",
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.9444444444444444\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.9444444444444444,\n",
      "    \"balanced_accuracy\": 0.9583333333333334,\n",
      "    \"mcc\": 0.9156002315160504\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models performance on the test dataset\n",
    "performance = predictor.evaluate(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora con los params de Udacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20211115_220755/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20211115_220755/\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    142\n",
      "Train Data Columns: 13\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [2, 1, 0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2559.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 119.86s of the 119.86s of remaining time.\n",
      "\t0.662\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 119.63s of the 119.62s of remaining time.\n",
      "\t0.7113\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 119.42s of the 119.41s of remaining time.\n",
      "No improvement since epoch 7: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "\t0.993\t = Validation score   (accuracy)\n",
      "\t6.05s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 112.92s of the 112.91s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t1.82s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 110.9s of the 110.89s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t1.56s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 109.12s of the 109.11s of remaining time.\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 108.31s of the 108.31s of remaining time.\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 107.49s of the 107.48s of remaining time.\n",
      "\t0.9718\t = Validation score   (accuracy)\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 105.53s of the 105.52s of remaining time.\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 104.69s of the 104.69s of remaining time.\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 103.86s of the 103.86s of remaining time.\n",
      "\t0.9718\t = Validation score   (accuracy)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 102.84s of the 102.84s of remaining time.\n",
      "\t0.9718\t = Validation score   (accuracy)\n",
      "\t14.49s\t = Training   runtime\n",
      "\t1.25s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 86.76s of the 86.75s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t3.24s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Repeating k-fold bagging: 2/20\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 83.09s of the 83.08s of remaining time.\n",
      "No improvement since epoch 5: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "\t0.993\t = Validation score   (accuracy)\n",
      "\t11.37s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 77.37s of the 77.36s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t3.31s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 75.68s of the 75.67s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9718\t = Validation score   (accuracy)\n",
      "\t3.16s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 73.88s of the 73.87s of remaining time.\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t2.87s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 72.63s of the 72.63s of remaining time.\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t1.35s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 71.61s of the 71.6s of remaining time.\n",
      "\t0.9648\t = Validation score   (accuracy)\n",
      "\t29.98s\t = Training   runtime\n",
      "\t2.68s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 54.33s of the 54.32s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9577\t = Validation score   (accuracy)\n",
      "\t6.66s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Repeating k-fold bagging: 3/20\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 50.64s of the 50.64s of remaining time.\n",
      "No improvement since epoch 3: early stopping\n",
      "No improvement since epoch 9: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t17.04s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 44.56s of the 44.55s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9718\t = Validation score   (accuracy)\n",
      "\t4.82s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 42.87s of the 42.86s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t4.72s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 41.13s of the 41.12s of remaining time.\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t4.87s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 38.95s of the 38.95s of remaining time.\n",
      "\t0.9718\t = Validation score   (accuracy)\n",
      "\t2.07s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 37.88s of the 37.88s of remaining time.\n",
      "\t0.9648\t = Validation score   (accuracy)\n",
      "\t41.98s\t = Training   runtime\n",
      "\t3.93s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 24.32s of the 24.32s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9648\t = Validation score   (accuracy)\n",
      "\t9.64s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Completed 3/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.86s of the 21.01s of remaining time.\n",
      "\t0.993\t = Validation score   (accuracy)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 99.46s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20211115_220755/\")\n"
     ]
    }
   ],
   "source": [
    "predictor2 = TabularPredictor(label='target').fit(\n",
    "  train_data=df_train,\n",
    "  # tuning_data=df_val,  \n",
    "  time_limit=120,\n",
    "  presets='best_quality'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                      model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       WeightedEnsemble_L2   0.992958       0.371883  27.522241                0.000401           0.287747            2       True         14\n",
      "1           CatBoost_BAG_L1   0.985915       0.026024   4.872167                0.026024           4.872167            1       True          8\n",
      "2   RandomForestGini_BAG_L1   0.985915       0.075641   0.606875                0.075641           0.606875            1       True          6\n",
      "3           LightGBM_BAG_L1   0.978873       0.049150   4.718175                0.049150           4.718175            1       True          5\n",
      "4   RandomForestEntr_BAG_L1   0.978873       0.073901   0.606196                0.073901           0.606196            1       True          7\n",
      "5     ExtraTreesGini_BAG_L1   0.978873       0.074533   0.613585                0.074533           0.613585            1       True          9\n",
      "6     ExtraTreesEntr_BAG_L1   0.978873       0.079816   0.608084                0.079816           0.608084            1       True         10\n",
      "7    NeuralNetFastAI_BAG_L1   0.978873       0.220667  17.037277                0.220667          17.037277            1       True          3\n",
      "8         LightGBMXT_BAG_L1   0.971831       0.050189   4.823705                0.050189           4.823705            1       True          4\n",
      "9            XGBoost_BAG_L1   0.971831       0.058181   2.072721                0.058181           2.072721            1       True         11\n",
      "10     LightGBMLarge_BAG_L1   0.964789       0.055879   9.641469                0.055879           9.641469            1       True         13\n",
      "11    NeuralNetMXNet_BAG_L1   0.964789       3.925439  41.984480                3.925439          41.984480            1       True         12\n",
      "12    KNeighborsDist_BAG_L1   0.711268       0.102369   0.009501                0.102369           0.009501            1       True          2\n",
      "13    KNeighborsUnif_BAG_L1   0.661972       0.103540   0.016952                0.103540           0.016952            1       True          1\n",
      "Number of models trained: 14\n",
      "Types of models trained:\n",
      "{'WeightedEnsembleModel', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_TabularNeuralNet', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_NNFastAiTabular'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', []) : 13 | ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', ...]\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20211115_220755/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForestGini_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'RandomForestEntr_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTreesGini_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'ExtraTreesEntr_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetMXNet_BAG_L1': 'StackerEnsembleModel_TabularNeuralNet',\n",
       "  'LightGBMLarge_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'KNeighborsUnif_BAG_L1': 0.6619718309859155,\n",
       "  'KNeighborsDist_BAG_L1': 0.7112676056338029,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.9788732394366197,\n",
       "  'LightGBMXT_BAG_L1': 0.971830985915493,\n",
       "  'LightGBM_BAG_L1': 0.9788732394366197,\n",
       "  'RandomForestGini_BAG_L1': 0.9859154929577465,\n",
       "  'RandomForestEntr_BAG_L1': 0.9788732394366197,\n",
       "  'CatBoost_BAG_L1': 0.9859154929577465,\n",
       "  'ExtraTreesGini_BAG_L1': 0.9788732394366197,\n",
       "  'ExtraTreesEntr_BAG_L1': 0.9788732394366197,\n",
       "  'XGBoost_BAG_L1': 0.971830985915493,\n",
       "  'NeuralNetMXNet_BAG_L1': 0.9647887323943662,\n",
       "  'LightGBMLarge_BAG_L1': 0.9647887323943662,\n",
       "  'WeightedEnsemble_L2': 0.9929577464788732},\n",
       " 'model_best': 'WeightedEnsemble_L2',\n",
       " 'model_paths': {'KNeighborsUnif_BAG_L1': 'AutogluonModels/ag-20211115_220755/models/KNeighborsUnif_BAG_L1/',\n",
       "  'KNeighborsDist_BAG_L1': 'AutogluonModels/ag-20211115_220755/models/KNeighborsDist_BAG_L1/',\n",
       "  'NeuralNetFastAI_BAG_L1': 'AutogluonModels/ag-20211115_220755/models/NeuralNetFastAI_BAG_L1/',\n",
       "  'LightGBMXT_BAG_L1': 'AutogluonModels/ag-20211115_220755/models/LightGBMXT_BAG_L1/',\n",
       "  'LightGBM_BAG_L1': 'AutogluonModels/ag-20211115_220755/models/LightGBM_BAG_L1/',\n",
       "  'RandomForestGini_BAG_L1': 'AutogluonModels/ag-20211115_220755/models/RandomForestGini_BAG_L1/',\n",
       "  'RandomForestEntr_BAG_L1': 'AutogluonModels/ag-20211115_220755/models/RandomForestEntr_BAG_L1/',\n",
       "  'CatBoost_BAG_L1': 'AutogluonModels/ag-20211115_220755/models/CatBoost_BAG_L1/',\n",
       "  'ExtraTreesGini_BAG_L1': 'AutogluonModels/ag-20211115_220755/models/ExtraTreesGini_BAG_L1/',\n",
       "  'ExtraTreesEntr_BAG_L1': 'AutogluonModels/ag-20211115_220755/models/ExtraTreesEntr_BAG_L1/',\n",
       "  'XGBoost_BAG_L1': 'AutogluonModels/ag-20211115_220755/models/XGBoost_BAG_L1/',\n",
       "  'NeuralNetMXNet_BAG_L1': 'AutogluonModels/ag-20211115_220755/models/NeuralNetMXNet_BAG_L1/',\n",
       "  'LightGBMLarge_BAG_L1': 'AutogluonModels/ag-20211115_220755/models/LightGBMLarge_BAG_L1/',\n",
       "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20211115_220755/models/WeightedEnsemble_L2/'},\n",
       " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 0.016951799392700195,\n",
       "  'KNeighborsDist_BAG_L1': 0.009500741958618164,\n",
       "  'NeuralNetFastAI_BAG_L1': 17.037277221679688,\n",
       "  'LightGBMXT_BAG_L1': 4.823705434799194,\n",
       "  'LightGBM_BAG_L1': 4.718174934387207,\n",
       "  'RandomForestGini_BAG_L1': 0.6068754196166992,\n",
       "  'RandomForestEntr_BAG_L1': 0.6061956882476807,\n",
       "  'CatBoost_BAG_L1': 4.872167110443115,\n",
       "  'ExtraTreesGini_BAG_L1': 0.6135847568511963,\n",
       "  'ExtraTreesEntr_BAG_L1': 0.6080842018127441,\n",
       "  'XGBoost_BAG_L1': 2.072720527648926,\n",
       "  'NeuralNetMXNet_BAG_L1': 41.984479904174805,\n",
       "  'LightGBMLarge_BAG_L1': 9.641468524932861,\n",
       "  'WeightedEnsemble_L2': 0.2877466678619385},\n",
       " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 0.10353994369506836,\n",
       "  'KNeighborsDist_BAG_L1': 0.10236883163452148,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.22066736221313477,\n",
       "  'LightGBMXT_BAG_L1': 0.05018925666809082,\n",
       "  'LightGBM_BAG_L1': 0.04915022850036621,\n",
       "  'RandomForestGini_BAG_L1': 0.07564115524291992,\n",
       "  'RandomForestEntr_BAG_L1': 0.07390069961547852,\n",
       "  'CatBoost_BAG_L1': 0.02602362632751465,\n",
       "  'ExtraTreesGini_BAG_L1': 0.07453346252441406,\n",
       "  'ExtraTreesEntr_BAG_L1': 0.07981610298156738,\n",
       "  'XGBoost_BAG_L1': 0.05818057060241699,\n",
       "  'NeuralNetMXNet_BAG_L1': 3.92543888092041,\n",
       "  'LightGBMLarge_BAG_L1': 0.05587887763977051,\n",
       "  'WeightedEnsemble_L2': 0.00040078163146972656},\n",
       " 'num_bag_folds': 5,\n",
       " 'max_stack_level': 2,\n",
       " 'num_classes': 3,\n",
       " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForestGini_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'RandomForestEntr_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTreesGini_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'ExtraTreesEntr_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetMXNet_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMLarge_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                       model  score_val  pred_time_val   fit_time  \\\n",
       " 0       WeightedEnsemble_L2   0.992958       0.371883  27.522241   \n",
       " 1           CatBoost_BAG_L1   0.985915       0.026024   4.872167   \n",
       " 2   RandomForestGini_BAG_L1   0.985915       0.075641   0.606875   \n",
       " 3           LightGBM_BAG_L1   0.978873       0.049150   4.718175   \n",
       " 4   RandomForestEntr_BAG_L1   0.978873       0.073901   0.606196   \n",
       " 5     ExtraTreesGini_BAG_L1   0.978873       0.074533   0.613585   \n",
       " 6     ExtraTreesEntr_BAG_L1   0.978873       0.079816   0.608084   \n",
       " 7    NeuralNetFastAI_BAG_L1   0.978873       0.220667  17.037277   \n",
       " 8         LightGBMXT_BAG_L1   0.971831       0.050189   4.823705   \n",
       " 9            XGBoost_BAG_L1   0.971831       0.058181   2.072721   \n",
       " 10     LightGBMLarge_BAG_L1   0.964789       0.055879   9.641469   \n",
       " 11    NeuralNetMXNet_BAG_L1   0.964789       3.925439  41.984480   \n",
       " 12    KNeighborsDist_BAG_L1   0.711268       0.102369   0.009501   \n",
       " 13    KNeighborsUnif_BAG_L1   0.661972       0.103540   0.016952   \n",
       " \n",
       "     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       " 0                 0.000401           0.287747            2       True   \n",
       " 1                 0.026024           4.872167            1       True   \n",
       " 2                 0.075641           0.606875            1       True   \n",
       " 3                 0.049150           4.718175            1       True   \n",
       " 4                 0.073901           0.606196            1       True   \n",
       " 5                 0.074533           0.613585            1       True   \n",
       " 6                 0.079816           0.608084            1       True   \n",
       " 7                 0.220667          17.037277            1       True   \n",
       " 8                 0.050189           4.823705            1       True   \n",
       " 9                 0.058181           2.072721            1       True   \n",
       " 10                0.055879           9.641469            1       True   \n",
       " 11                3.925439          41.984480            1       True   \n",
       " 12                0.102369           0.009501            1       True   \n",
       " 13                0.103540           0.016952            1       True   \n",
       " \n",
       "     fit_order  \n",
       " 0          14  \n",
       " 1           8  \n",
       " 2           6  \n",
       " 3           5  \n",
       " 4           7  \n",
       " 5           9  \n",
       " 6          10  \n",
       " 7           3  \n",
       " 8           4  \n",
       " 9          11  \n",
       " 10         13  \n",
       " 11         12  \n",
       " 12          2  \n",
       " 13          1  }"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor2.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.9722222222222222\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.9722222222222222,\n",
      "    \"balanced_accuracy\": 0.9791666666666666,\n",
      "    \"mcc\": 0.9572184238576891\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9722222222222222,\n",
       " 'balanced_accuracy': 0.9791666666666666,\n",
       " 'mcc': 0.9572184238576891}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = predictor2.evaluate(df_test)\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGluon Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0.019913</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.104809</td>\n",
       "      <td>0.070073</td>\n",
       "      <td>-0.035968</td>\n",
       "      <td>-0.026679</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>0.040343</td>\n",
       "      <td>321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>-0.012780</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.060618</td>\n",
       "      <td>0.052858</td>\n",
       "      <td>0.047965</td>\n",
       "      <td>0.029375</td>\n",
       "      <td>-0.017629</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.070211</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.008883</td>\n",
       "      <td>0.042530</td>\n",
       "      <td>-0.042848</td>\n",
       "      <td>-0.021042</td>\n",
       "      <td>-0.039719</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>-0.012780</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.023451</td>\n",
       "      <td>-0.040099</td>\n",
       "      <td>-0.016704</td>\n",
       "      <td>0.004636</td>\n",
       "      <td>-0.017629</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.038459</td>\n",
       "      <td>-0.038357</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>-0.023677</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.045529</td>\n",
       "      <td>0.090730</td>\n",
       "      <td>-0.018080</td>\n",
       "      <td>-0.035447</td>\n",
       "      <td>0.070730</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.034524</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "362  0.019913  0.050680  0.104809  0.070073 -0.035968 -0.026679 -0.024993   \n",
       "249 -0.012780 -0.044642  0.060618  0.052858  0.047965  0.029375 -0.017629   \n",
       "271  0.038076  0.050680  0.008883  0.042530 -0.042848 -0.021042 -0.039719   \n",
       "435 -0.012780 -0.044642 -0.023451 -0.040099 -0.016704  0.004636 -0.017629   \n",
       "400 -0.023677 -0.044642  0.045529  0.090730 -0.018080 -0.035447  0.070730   \n",
       "\n",
       "           s4        s5        s6  target  \n",
       "362 -0.002592  0.003712  0.040343   321.0  \n",
       "249  0.034309  0.070211  0.007207   215.0  \n",
       "271 -0.002592 -0.018118  0.007207   127.0  \n",
       "435 -0.002592 -0.038459 -0.038357    64.0  \n",
       "400 -0.039493 -0.034524 -0.009362   175.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the diabetes `data` dataset as a dataframe and name the columns with `feature_names`\n",
    "dfd = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "\n",
    "# Include the target as well\n",
    "dfd['target'] = diabetes.target\n",
    "dfd.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data with these ratios: train: 0.8 | test: 0.2\n",
    "dfd_train, dfd_test = train_test_split(dfd, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20211115_223156/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20211115_223156/\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    353\n",
      "Train Data Columns: 10\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (346.0, 25.0, 151.60623, 78.40991)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2526.79 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['age', 'sex', 'bmi', 'bp', 's1', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 9 | ['age', 'bmi', 'bp', 's1', 's2', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 282, Val Rows: 71\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-70.061\t = Validation score   (root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-69.8056\t = Validation score   (root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t-57.3877\t = Validation score   (root_mean_squared_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t-59.5989\t = Validation score   (root_mean_squared_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-61.2732\t = Validation score   (root_mean_squared_error)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-59.1372\t = Validation score   (root_mean_squared_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-58.5095\t = Validation score   (root_mean_squared_error)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-58.6728\t = Validation score   (root_mean_squared_error)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-66.5692\t = Validation score   (root_mean_squared_error)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\t-62.2187\t = Validation score   (root_mean_squared_error)\n",
      "\t4.48s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t-65.0328\t = Validation score   (root_mean_squared_error)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-57.1814\t = Validation score   (root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11.23s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20211115_223156/\")\n"
     ]
    }
   ],
   "source": [
    "# How does the model perform on the training dataset and default model parameters?\n",
    "# Using the hyperparameters in the requirements, is there improvement?\n",
    "# Remember we use the test dataset to score the model\n",
    "# No need to explicitly say this is a regression, autogluon will pick it up\n",
    "predictor = TabularPredictor(label='target').fit(\n",
    "dfd_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model  score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L2 -57.181381       0.020760  1.370624                0.000363           0.228441            2       True         12\n",
      "1            LightGBMXT -57.387735       0.004924  0.376891                0.004924           0.376891            1       True          3\n",
      "2         ExtraTreesMSE -58.509493       0.102410  0.503781                0.102410           0.503781            1       True          7\n",
      "3       NeuralNetFastAI -58.672760       0.015472  0.765291                0.015472           0.765291            1       True          8\n",
      "4              CatBoost -59.137172       0.001323  0.330103                0.001323           0.330103            1       True          6\n",
      "5              LightGBM -59.598910       0.003630  0.352861                0.003630           0.352861            1       True          4\n",
      "6       RandomForestMSE -61.273237       0.102411  0.603903                0.102411           0.603903            1       True          5\n",
      "7        NeuralNetMXNet -62.218710       0.252260  4.478350                0.252260           4.478350            1       True         10\n",
      "8         LightGBMLarge -65.032821       0.003950  0.464960                0.003950           0.464960            1       True         11\n",
      "9               XGBoost -66.569236       0.004725  0.457219                0.004725           0.457219            1       True          9\n",
      "10       KNeighborsDist -69.805557       0.102726  0.008967                0.102726           0.008967            1       True          2\n",
      "11       KNeighborsUnif -70.061004       0.104103  0.025495                0.104103           0.025495            1       True          1\n",
      "Number of models trained: 12\n",
      "Types of models trained:\n",
      "{'WeightedEnsembleModel', 'XTModel', 'RFModel', 'CatBoostModel', 'XGBoostModel', 'NNFastAiTabularModel', 'KNNModel', 'TabularNeuralNetModel', 'LGBModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 9 | ['age', 'bmi', 'bp', 's1', 's2', ...]\n",
      "('int', ['bool']) : 1 | ['sex']\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20211115_223156/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'KNeighborsUnif': 'KNNModel',\n",
       "  'KNeighborsDist': 'KNNModel',\n",
       "  'LightGBMXT': 'LGBModel',\n",
       "  'LightGBM': 'LGBModel',\n",
       "  'RandomForestMSE': 'RFModel',\n",
       "  'CatBoost': 'CatBoostModel',\n",
       "  'ExtraTreesMSE': 'XTModel',\n",
       "  'NeuralNetFastAI': 'NNFastAiTabularModel',\n",
       "  'XGBoost': 'XGBoostModel',\n",
       "  'NeuralNetMXNet': 'TabularNeuralNetModel',\n",
       "  'LightGBMLarge': 'LGBModel',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'KNeighborsUnif': -70.0610036829987,\n",
       "  'KNeighborsDist': -69.80555708245664,\n",
       "  'LightGBMXT': -57.38773539223603,\n",
       "  'LightGBM': -59.598909787140585,\n",
       "  'RandomForestMSE': -61.27323702586723,\n",
       "  'CatBoost': -59.13717205495789,\n",
       "  'ExtraTreesMSE': -58.5094933037308,\n",
       "  'NeuralNetFastAI': -58.672759752671745,\n",
       "  'XGBoost': -66.56923598047658,\n",
       "  'NeuralNetMXNet': -62.218709782042254,\n",
       "  'LightGBMLarge': -65.03282131536429,\n",
       "  'WeightedEnsemble_L2': -57.18138101878208},\n",
       " 'model_best': 'WeightedEnsemble_L2',\n",
       " 'model_paths': {'KNeighborsUnif': 'AutogluonModels/ag-20211115_223156/models/KNeighborsUnif/',\n",
       "  'KNeighborsDist': 'AutogluonModels/ag-20211115_223156/models/KNeighborsDist/',\n",
       "  'LightGBMXT': 'AutogluonModels/ag-20211115_223156/models/LightGBMXT/',\n",
       "  'LightGBM': 'AutogluonModels/ag-20211115_223156/models/LightGBM/',\n",
       "  'RandomForestMSE': 'AutogluonModels/ag-20211115_223156/models/RandomForestMSE/',\n",
       "  'CatBoost': 'AutogluonModels/ag-20211115_223156/models/CatBoost/',\n",
       "  'ExtraTreesMSE': 'AutogluonModels/ag-20211115_223156/models/ExtraTreesMSE/',\n",
       "  'NeuralNetFastAI': 'AutogluonModels/ag-20211115_223156/models/NeuralNetFastAI/',\n",
       "  'XGBoost': 'AutogluonModels/ag-20211115_223156/models/XGBoost/',\n",
       "  'NeuralNetMXNet': 'AutogluonModels/ag-20211115_223156/models/NeuralNetMXNet/',\n",
       "  'LightGBMLarge': 'AutogluonModels/ag-20211115_223156/models/LightGBMLarge/',\n",
       "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20211115_223156/models/WeightedEnsemble_L2/'},\n",
       " 'model_fit_times': {'KNeighborsUnif': 0.025495052337646484,\n",
       "  'KNeighborsDist': 0.008966922760009766,\n",
       "  'LightGBMXT': 0.3768906593322754,\n",
       "  'LightGBM': 0.3528609275817871,\n",
       "  'RandomForestMSE': 0.6039025783538818,\n",
       "  'CatBoost': 0.33010315895080566,\n",
       "  'ExtraTreesMSE': 0.5037813186645508,\n",
       "  'NeuralNetFastAI': 0.7652914524078369,\n",
       "  'XGBoost': 0.45721936225891113,\n",
       "  'NeuralNetMXNet': 4.478349924087524,\n",
       "  'LightGBMLarge': 0.46495962142944336,\n",
       "  'WeightedEnsemble_L2': 0.22844147682189941},\n",
       " 'model_pred_times': {'KNeighborsUnif': 0.10410308837890625,\n",
       "  'KNeighborsDist': 0.10272598266601562,\n",
       "  'LightGBMXT': 0.004924297332763672,\n",
       "  'LightGBM': 0.003629922866821289,\n",
       "  'RandomForestMSE': 0.10241079330444336,\n",
       "  'CatBoost': 0.0013225078582763672,\n",
       "  'ExtraTreesMSE': 0.10241007804870605,\n",
       "  'NeuralNetFastAI': 0.015472173690795898,\n",
       "  'XGBoost': 0.0047245025634765625,\n",
       "  'NeuralNetMXNet': 0.2522602081298828,\n",
       "  'LightGBMLarge': 0.003949642181396484,\n",
       "  'WeightedEnsemble_L2': 0.00036334991455078125},\n",
       " 'num_bag_folds': 0,\n",
       " 'max_stack_level': 2,\n",
       " 'model_hyperparams': {'KNeighborsUnif': {'weights': 'uniform', 'n_jobs': -1},\n",
       "  'KNeighborsDist': {'weights': 'distance', 'n_jobs': -1},\n",
       "  'LightGBMXT': {'num_boost_round': 10000,\n",
       "   'num_threads': -1,\n",
       "   'learning_rate': 0.05,\n",
       "   'objective': 'regression',\n",
       "   'verbose': -1,\n",
       "   'boosting_type': 'gbdt',\n",
       "   'two_round': True,\n",
       "   'extra_trees': True},\n",
       "  'LightGBM': {'num_boost_round': 10000,\n",
       "   'num_threads': -1,\n",
       "   'learning_rate': 0.05,\n",
       "   'objective': 'regression',\n",
       "   'verbose': -1,\n",
       "   'boosting_type': 'gbdt',\n",
       "   'two_round': True},\n",
       "  'RandomForestMSE': {'n_estimators': 300,\n",
       "   'n_jobs': -1,\n",
       "   'random_state': 0,\n",
       "   'bootstrap': True,\n",
       "   'criterion': 'mse'},\n",
       "  'CatBoost': {'iterations': 10000,\n",
       "   'learning_rate': 0.05,\n",
       "   'random_seed': 0,\n",
       "   'allow_writing_files': False,\n",
       "   'eval_metric': 'RMSE'},\n",
       "  'ExtraTreesMSE': {'n_estimators': 300,\n",
       "   'n_jobs': -1,\n",
       "   'random_state': 0,\n",
       "   'bootstrap': True,\n",
       "   'criterion': 'mse'},\n",
       "  'NeuralNetFastAI': {'layers': None,\n",
       "   'emb_drop': 0.1,\n",
       "   'ps': 0.1,\n",
       "   'bs': 256,\n",
       "   'lr': 0.01,\n",
       "   'epochs': 30,\n",
       "   'early.stopping.min_delta': 0.0001,\n",
       "   'early.stopping.patience': 20,\n",
       "   'smoothing': 0.0},\n",
       "  'XGBoost': {'n_estimators': 10000,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_jobs': -1,\n",
       "   'proc.max_category_levels': 100,\n",
       "   'objective': 'reg:squarederror',\n",
       "   'booster': 'gbtree'},\n",
       "  'NeuralNetMXNet': {'num_epochs': 500,\n",
       "   'epochs_wo_improve': 20,\n",
       "   'seed_value': None,\n",
       "   'proc.embed_min_categories': 4,\n",
       "   'proc.impute_strategy': 'median',\n",
       "   'proc.max_category_levels': 100,\n",
       "   'proc.skew_threshold': 0.99,\n",
       "   'network_type': 'widedeep',\n",
       "   'layers': None,\n",
       "   'numeric_embed_dim': None,\n",
       "   'activation': 'relu',\n",
       "   'max_layer_width': 2056,\n",
       "   'embedding_size_factor': 1.0,\n",
       "   'embed_exponent': 0.56,\n",
       "   'max_embedding_dim': 100,\n",
       "   'y_range': None,\n",
       "   'y_range_extend': 0.05,\n",
       "   'use_batchnorm': True,\n",
       "   'dropout_prob': 0.1,\n",
       "   'batch_size': 512,\n",
       "   'loss_function': None,\n",
       "   'optimizer': 'adam',\n",
       "   'learning_rate': 0.0003,\n",
       "   'weight_decay': 1e-06,\n",
       "   'clip_gradient': 100.0,\n",
       "   'momentum': 0.9,\n",
       "   'lr_scheduler': None,\n",
       "   'base_lr': 3e-05,\n",
       "   'target_lr': 1.0,\n",
       "   'lr_decay': 0.1,\n",
       "   'warmup_epochs': 10,\n",
       "   'use_ngram_features': False},\n",
       "  'LightGBMLarge': {'num_boost_round': 10000,\n",
       "   'num_threads': -1,\n",
       "   'learning_rate': 0.03,\n",
       "   'objective': 'regression',\n",
       "   'verbose': -1,\n",
       "   'boosting_type': 'gbdt',\n",
       "   'two_round': True,\n",
       "   'num_leaves': 128,\n",
       "   'feature_fraction': 0.9,\n",
       "   'min_data_in_leaf': 5},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                   model  score_val  pred_time_val  fit_time  \\\n",
       " 0   WeightedEnsemble_L2 -57.181381       0.020760  1.370624   \n",
       " 1            LightGBMXT -57.387735       0.004924  0.376891   \n",
       " 2         ExtraTreesMSE -58.509493       0.102410  0.503781   \n",
       " 3       NeuralNetFastAI -58.672760       0.015472  0.765291   \n",
       " 4              CatBoost -59.137172       0.001323  0.330103   \n",
       " 5              LightGBM -59.598910       0.003630  0.352861   \n",
       " 6       RandomForestMSE -61.273237       0.102411  0.603903   \n",
       " 7        NeuralNetMXNet -62.218710       0.252260  4.478350   \n",
       " 8         LightGBMLarge -65.032821       0.003950  0.464960   \n",
       " 9               XGBoost -66.569236       0.004725  0.457219   \n",
       " 10       KNeighborsDist -69.805557       0.102726  0.008967   \n",
       " 11       KNeighborsUnif -70.061004       0.104103  0.025495   \n",
       " \n",
       "     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       " 0                 0.000363           0.228441            2       True   \n",
       " 1                 0.004924           0.376891            1       True   \n",
       " 2                 0.102410           0.503781            1       True   \n",
       " 3                 0.015472           0.765291            1       True   \n",
       " 4                 0.001323           0.330103            1       True   \n",
       " 5                 0.003630           0.352861            1       True   \n",
       " 6                 0.102411           0.603903            1       True   \n",
       " 7                 0.252260           4.478350            1       True   \n",
       " 8                 0.003950           0.464960            1       True   \n",
       " 9                 0.004725           0.457219            1       True   \n",
       " 10                0.102726           0.008967            1       True   \n",
       " 11                0.104103           0.025495            1       True   \n",
       " \n",
       "     fit_order  \n",
       " 0          12  \n",
       " 1           3  \n",
       " 2           7  \n",
       " 3           8  \n",
       " 4           6  \n",
       " 5           4  \n",
       " 6           5  \n",
       " 7          10  \n",
       " 8          11  \n",
       " 9           9  \n",
       " 10          2  \n",
       " 11          1  }"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the fit summary of the training run\n",
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: root_mean_squared_error on test data: -55.407477745920616\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -55.407477745920616,\n",
      "    \"mean_squared_error\": -3069.988590164688,\n",
      "    \"mean_absolute_error\": -43.7481920906667,\n",
      "    \"r2\": 0.40131975892905214,\n",
      "    \"pearsonr\": 0.6335014529299379,\n",
      "    \"median_absolute_error\": -37.09673309326172\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models performance on the test dataset\n",
    "performance = predictor.evaluate(dfd_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora con params de udacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20211115_225656/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20211115_225656/\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    353\n",
      "Train Data Columns: 10\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2453.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['age', 'sex', 'bmi', 'bp', 's1', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 9 | ['age', 'bmi', 'bp', 's1', 's2', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 299.84s of the 299.84s of remaining time.\n",
      "\t0.4305\t = Validation score   (r2)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 299.61s of the 299.61s of remaining time.\n",
      "\t0.4397\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 299.4s of the 299.39s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.5416\t = Validation score   (r2)\n",
      "\t5.06s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 293.94s of the 293.94s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.514\t = Validation score   (r2)\n",
      "\t3.71s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 289.94s of the 289.93s of remaining time.\n",
      "\t0.4667\t = Validation score   (r2)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 288.98s of the 288.98s of remaining time.\n",
      "\t0.5228\t = Validation score   (r2)\n",
      "\t2.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 286.69s of the 286.69s of remaining time.\n",
      "\t0.5022\t = Validation score   (r2)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 285.85s of the 285.85s of remaining time.\n",
      "\t0.4878\t = Validation score   (r2)\n",
      "\t3.85s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 281.6s of the 281.6s of remaining time.\n",
      "\t0.4456\t = Validation score   (r2)\n",
      "\t2.59s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 278.54s of the 278.53s of remaining time.\n",
      "\t0.4768\t = Validation score   (r2)\n",
      "\t22.22s\t = Training   runtime\n",
      "\t1.71s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 254.3s of the 254.29s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.4569\t = Validation score   (r2)\n",
      "\t4.61s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Repeating k-fold bagging: 2/20\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 249.34s of the 249.34s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.5455\t = Validation score   (r2)\n",
      "\t9.13s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 244.97s of the 244.96s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.5209\t = Validation score   (r2)\n",
      "\t7.34s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 241.07s of the 241.07s of remaining time.\n",
      "\t0.5223\t = Validation score   (r2)\n",
      "\t4.08s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 238.78s of the 238.77s of remaining time.\n",
      "\t0.4918\t = Validation score   (r2)\n",
      "\t7.98s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 234.21s of the 234.21s of remaining time.\n",
      "\t0.4447\t = Validation score   (r2)\n",
      "\t5.63s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 230.66s of the 230.65s of remaining time.\n",
      "\t0.4927\t = Validation score   (r2)\n",
      "\t45.0s\t = Training   runtime\n",
      "\t3.4s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 205.87s of the 205.87s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.4691\t = Validation score   (r2)\n",
      "\t9.0s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Repeating k-fold bagging: 3/20\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 201.14s of the 201.13s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.5484\t = Validation score   (r2)\n",
      "\t12.78s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 197.25s of the 197.24s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.5265\t = Validation score   (r2)\n",
      "\t10.66s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 193.69s of the 193.68s of remaining time.\n",
      "\t0.5231\t = Validation score   (r2)\n",
      "\t6.07s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 191.44s of the 191.43s of remaining time.\n",
      "\t0.4941\t = Validation score   (r2)\n",
      "\t11.81s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 187.2s of the 187.2s of remaining time.\n",
      "\t0.4522\t = Validation score   (r2)\n",
      "\t8.4s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 183.98s of the 183.97s of remaining time.\n",
      "\t0.5059\t = Validation score   (r2)\n",
      "\t67.22s\t = Training   runtime\n",
      "\t5.15s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 159.69s of the 159.68s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.4743\t = Validation score   (r2)\n",
      "\t13.15s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Repeating k-fold bagging: 4/20\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 155.23s of the 155.22s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.5478\t = Validation score   (r2)\n",
      "\t16.68s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 151.07s of the 151.06s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.5283\t = Validation score   (r2)\n",
      "\t14.4s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 147.08s of the 147.08s of remaining time.\n",
      "\t0.5226\t = Validation score   (r2)\n",
      "\t7.8s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 145.1s of the 145.1s of remaining time.\n",
      "\t0.5021\t = Validation score   (r2)\n",
      "\t15.63s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 140.86s of the 140.86s of remaining time.\n",
      "\t0.4587\t = Validation score   (r2)\n",
      "\t11.43s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 137.36s of the 137.35s of remaining time.\n",
      "\t0.5074\t = Validation score   (r2)\n",
      "\t94.14s\t = Training   runtime\n",
      "\t6.96s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 108.31s of the 108.3s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.4785\t = Validation score   (r2)\n",
      "\t17.57s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Repeating k-fold bagging: 5/20\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 103.54s of the 103.54s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.5473\t = Validation score   (r2)\n",
      "\t20.64s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 99.29s of the 99.29s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.5289\t = Validation score   (r2)\n",
      "\t17.83s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 95.61s of the 95.61s of remaining time.\n",
      "\t0.5253\t = Validation score   (r2)\n",
      "\t9.78s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 93.39s of the 93.38s of remaining time.\n",
      "\t0.5043\t = Validation score   (r2)\n",
      "\t19.46s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 89.14s of the 89.13s of remaining time.\n",
      "\t0.4608\t = Validation score   (r2)\n",
      "\t14.22s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 85.89s of the 85.89s of remaining time.\n",
      "\t0.5076\t = Validation score   (r2)\n",
      "\t117.06s\t = Training   runtime\n",
      "\t8.73s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 60.88s of the 60.88s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.4789\t = Validation score   (r2)\n",
      "\t21.68s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Completed 5/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.84s of the 56.41s of remaining time.\n",
      "\t0.5488\t = Validation score   (r2)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 244.05s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20211115_225656/\")\n"
     ]
    }
   ],
   "source": [
    "predictor2 = TabularPredictor(\n",
    "    label='target', \n",
    "    eval_metric='r2',\n",
    "    problem_type='regression'\n",
    ").fit(\n",
    "  dfd_train,\n",
    "  time_limit=300,\n",
    "  presets='best_quality'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                     model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      WeightedEnsemble_L2   0.548834       8.940636  155.819073                0.000450           0.286379            2       True         12\n",
      "1        LightGBMXT_BAG_L1   0.547344       0.119675   20.640190                0.119675          20.640190            1       True          3\n",
      "2          LightGBM_BAG_L1   0.528903       0.092032   17.833634                0.092032          17.833634            1       True          4\n",
      "3          CatBoost_BAG_L1   0.525317       0.046124    9.784431                0.046124           9.784431            1       True          6\n",
      "4    NeuralNetMXNet_BAG_L1   0.507561       8.728479  117.058870                8.728479         117.058870            1       True         10\n",
      "5   NeuralNetFastAI_BAG_L1   0.504251       0.379363   19.464737                0.379363          19.464737            1       True          8\n",
      "6     ExtraTreesMSE_BAG_L1   0.502246       0.090744    0.498836                0.090744           0.498836            1       True          7\n",
      "7     LightGBMLarge_BAG_L1   0.478857       0.098045   21.677391                0.098045          21.677391            1       True         11\n",
      "8   RandomForestMSE_BAG_L1   0.466743       0.078594    0.598291                0.078594           0.598291            1       True          5\n",
      "9           XGBoost_BAG_L1   0.460809       0.130967   14.221055                0.130967          14.221055            1       True          9\n",
      "10   KNeighborsDist_BAG_L1   0.439701       0.103431    0.013557                0.103431           0.013557            1       True          2\n",
      "11   KNeighborsUnif_BAG_L1   0.430521       0.102343    0.015361                0.102343           0.015361            1       True          1\n",
      "Number of models trained: 12\n",
      "Types of models trained:\n",
      "{'WeightedEnsembleModel', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_TabularNeuralNet', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_NNFastAiTabular'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 9 | ['age', 'bmi', 'bp', 's1', 's2', ...]\n",
      "('int', ['bool']) : 1 | ['sex']\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20211115_225656/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForestMSE_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTreesMSE_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetMXNet_BAG_L1': 'StackerEnsembleModel_TabularNeuralNet',\n",
       "  'LightGBMLarge_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'KNeighborsUnif_BAG_L1': 0.43052099899418794,\n",
       "  'KNeighborsDist_BAG_L1': 0.43970122394744415,\n",
       "  'LightGBMXT_BAG_L1': 0.5473443233566178,\n",
       "  'LightGBM_BAG_L1': 0.5289027578439717,\n",
       "  'RandomForestMSE_BAG_L1': 0.4667434753086127,\n",
       "  'CatBoost_BAG_L1': 0.5253171382571247,\n",
       "  'ExtraTreesMSE_BAG_L1': 0.502246448213272,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.5042511058747634,\n",
       "  'XGBoost_BAG_L1': 0.460809487787041,\n",
       "  'NeuralNetMXNet_BAG_L1': 0.5075606725642667,\n",
       "  'LightGBMLarge_BAG_L1': 0.4788568526418864,\n",
       "  'WeightedEnsemble_L2': 0.5488335255420552},\n",
       " 'model_best': 'WeightedEnsemble_L2',\n",
       " 'model_paths': {'KNeighborsUnif_BAG_L1': 'AutogluonModels/ag-20211115_225656/models/KNeighborsUnif_BAG_L1/',\n",
       "  'KNeighborsDist_BAG_L1': 'AutogluonModels/ag-20211115_225656/models/KNeighborsDist_BAG_L1/',\n",
       "  'LightGBMXT_BAG_L1': 'AutogluonModels/ag-20211115_225656/models/LightGBMXT_BAG_L1/',\n",
       "  'LightGBM_BAG_L1': 'AutogluonModels/ag-20211115_225656/models/LightGBM_BAG_L1/',\n",
       "  'RandomForestMSE_BAG_L1': 'AutogluonModels/ag-20211115_225656/models/RandomForestMSE_BAG_L1/',\n",
       "  'CatBoost_BAG_L1': 'AutogluonModels/ag-20211115_225656/models/CatBoost_BAG_L1/',\n",
       "  'ExtraTreesMSE_BAG_L1': 'AutogluonModels/ag-20211115_225656/models/ExtraTreesMSE_BAG_L1/',\n",
       "  'NeuralNetFastAI_BAG_L1': 'AutogluonModels/ag-20211115_225656/models/NeuralNetFastAI_BAG_L1/',\n",
       "  'XGBoost_BAG_L1': 'AutogluonModels/ag-20211115_225656/models/XGBoost_BAG_L1/',\n",
       "  'NeuralNetMXNet_BAG_L1': 'AutogluonModels/ag-20211115_225656/models/NeuralNetMXNet_BAG_L1/',\n",
       "  'LightGBMLarge_BAG_L1': 'AutogluonModels/ag-20211115_225656/models/LightGBMLarge_BAG_L1/',\n",
       "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20211115_225656/models/WeightedEnsemble_L2/'},\n",
       " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 0.015360832214355469,\n",
       "  'KNeighborsDist_BAG_L1': 0.01355743408203125,\n",
       "  'LightGBMXT_BAG_L1': 20.640190362930298,\n",
       "  'LightGBM_BAG_L1': 17.83363437652588,\n",
       "  'RandomForestMSE_BAG_L1': 0.5982911586761475,\n",
       "  'CatBoost_BAG_L1': 9.784431219100952,\n",
       "  'ExtraTreesMSE_BAG_L1': 0.4988362789154053,\n",
       "  'NeuralNetFastAI_BAG_L1': 19.46473741531372,\n",
       "  'XGBoost_BAG_L1': 14.221055030822754,\n",
       "  'NeuralNetMXNet_BAG_L1': 117.05886960029602,\n",
       "  'LightGBMLarge_BAG_L1': 21.677391290664673,\n",
       "  'WeightedEnsemble_L2': 0.2863788604736328},\n",
       " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 0.10234284400939941,\n",
       "  'KNeighborsDist_BAG_L1': 0.10343122482299805,\n",
       "  'LightGBMXT_BAG_L1': 0.1196753978729248,\n",
       "  'LightGBM_BAG_L1': 0.09203219413757324,\n",
       "  'RandomForestMSE_BAG_L1': 0.07859373092651367,\n",
       "  'CatBoost_BAG_L1': 0.04612445831298828,\n",
       "  'ExtraTreesMSE_BAG_L1': 0.0907440185546875,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.3793630599975586,\n",
       "  'XGBoost_BAG_L1': 0.1309671401977539,\n",
       "  'NeuralNetMXNet_BAG_L1': 8.728478908538818,\n",
       "  'LightGBMLarge_BAG_L1': 0.09804487228393555,\n",
       "  'WeightedEnsemble_L2': 0.0004496574401855469},\n",
       " 'num_bag_folds': 5,\n",
       " 'max_stack_level': 2,\n",
       " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForestMSE_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTreesMSE_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetMXNet_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMLarge_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                      model  score_val  pred_time_val    fit_time  \\\n",
       " 0      WeightedEnsemble_L2   0.548834       8.940636  155.819073   \n",
       " 1        LightGBMXT_BAG_L1   0.547344       0.119675   20.640190   \n",
       " 2          LightGBM_BAG_L1   0.528903       0.092032   17.833634   \n",
       " 3          CatBoost_BAG_L1   0.525317       0.046124    9.784431   \n",
       " 4    NeuralNetMXNet_BAG_L1   0.507561       8.728479  117.058870   \n",
       " 5   NeuralNetFastAI_BAG_L1   0.504251       0.379363   19.464737   \n",
       " 6     ExtraTreesMSE_BAG_L1   0.502246       0.090744    0.498836   \n",
       " 7     LightGBMLarge_BAG_L1   0.478857       0.098045   21.677391   \n",
       " 8   RandomForestMSE_BAG_L1   0.466743       0.078594    0.598291   \n",
       " 9           XGBoost_BAG_L1   0.460809       0.130967   14.221055   \n",
       " 10   KNeighborsDist_BAG_L1   0.439701       0.103431    0.013557   \n",
       " 11   KNeighborsUnif_BAG_L1   0.430521       0.102343    0.015361   \n",
       " \n",
       "     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       " 0                 0.000450           0.286379            2       True   \n",
       " 1                 0.119675          20.640190            1       True   \n",
       " 2                 0.092032          17.833634            1       True   \n",
       " 3                 0.046124           9.784431            1       True   \n",
       " 4                 8.728479         117.058870            1       True   \n",
       " 5                 0.379363          19.464737            1       True   \n",
       " 6                 0.090744           0.498836            1       True   \n",
       " 7                 0.098045          21.677391            1       True   \n",
       " 8                 0.078594           0.598291            1       True   \n",
       " 9                 0.130967          14.221055            1       True   \n",
       " 10                0.103431           0.013557            1       True   \n",
       " 11                0.102343           0.015361            1       True   \n",
       " \n",
       "     fit_order  \n",
       " 0          12  \n",
       " 1           3  \n",
       " 2           4  \n",
       " 3           6  \n",
       " 4          10  \n",
       " 5           8  \n",
       " 6           7  \n",
       " 7          11  \n",
       " 8           5  \n",
       " 9           9  \n",
       " 10          2  \n",
       " 11          1  }"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor2.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4514966dd0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictor2.leaderboard(silent=True).plot(kind=\"bar\", x=\"model\", y=\"score_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: r2 on test data: 0.3296197110735112\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"r2\": 0.3296197110735112,\n",
      "    \"root_mean_squared_error\": -58.63157173036981,\n",
      "    \"mean_squared_error\": -3437.6612035734997,\n",
      "    \"mean_absolute_error\": -44.644462671172754,\n",
      "    \"pearsonr\": 0.5866496596979706,\n",
      "    \"median_absolute_error\": -36.31768798828125\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'r2': 0.3296197110735112,\n",
       " 'root_mean_squared_error': -58.63157173036981,\n",
       " 'mean_squared_error': -3437.6612035734997,\n",
       " 'mean_absolute_error': -44.644462671172754,\n",
       " 'pearsonr': 0.5866496596979706,\n",
       " 'median_absolute_error': -36.31768798828125}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor2.evaluate(dfd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
